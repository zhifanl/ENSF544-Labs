{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees - Example\n",
    "\n",
    "Apply a Random Forest classifier, `RandomForest()` to the heart disease dataset\n",
    "\n",
    "The data is hosted on UCI https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "we will need `load_heart_disease()` from the `Linear Example.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data\n",
    "**Question:** Can you update the function `load_heart_disease()` to download the file from the url if the file is not on disk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_heart_disease():\n",
    "    '''Load and pre-process heart disease data\n",
    "    \n",
    "    if processed.hungarian.data file is not present.\n",
    "    \n",
    "    it will be downloaded from\n",
    "    https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\n",
    "    \n",
    "    return: data(DataFrame)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    \n",
    "    file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "    file_name = file_url.split('/')[-1]\n",
    "    \n",
    "    if not os.path.isfile(file_name):\n",
    "        print('Downloading from {}'.format(file_url))\n",
    "        r = requests.get(file_url)\n",
    "        with open(file_name,'wb') as output_file:\n",
    "            output_file.write(r.content)\n",
    "        \n",
    "    data = pd.read_csv(file_name, \n",
    "                   na_values='?', \n",
    "                   names=[ 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',\n",
    "                            'restecg', 'thalach', 'exang', 'oldpeak', 'slope',\n",
    "                            'ca', 'thal', 'num'])\n",
    "    \n",
    "    # drop columns with many missing data\n",
    "    data = data.drop(columns=['slope', 'ca', 'thal'])\n",
    "    \n",
    "    # fill in remaining missing data with mean() per column\n",
    "    data = data.fillna(data.mean())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294 entries, 0 to 293\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       294 non-null    int64  \n",
      " 1   sex       294 non-null    int64  \n",
      " 2   cp        294 non-null    int64  \n",
      " 3   trestbps  294 non-null    float64\n",
      " 4   chol      294 non-null    float64\n",
      " 5   fbs       294 non-null    float64\n",
      " 6   restecg   294 non-null    float64\n",
      " 7   thalach   294 non-null    float64\n",
      " 8   exang     294 non-null    float64\n",
      " 9   oldpeak   294 non-null    float64\n",
      " 10  num       294 non-null    int64  \n",
      "dtypes: float64(7), int64(4)\n",
      "memory usage: 25.4 KB\n"
     ]
    }
   ],
   "source": [
    "data = load_heart_disease()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature matrix and target vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 10)\n",
      "(294,)\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix and target vector and print shapes\n",
    "X = data.drop(columns='num')\n",
    "y = data['num']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 10)\n",
      "(30, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.1,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=31)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    169\n",
       "1     95\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    19\n",
       "1    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply `RandomForest()` and evaluate the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=58)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation \n",
    "\n",
    "Are we over- or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `cross_val_score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `cross_validate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(model, X_train, y_train, cv=5, \n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means\n",
    "for label_pair in [ ('train_score', 'train_score'), ('test_score', 'validation_score')]:\n",
    "    print('{} = {:.3f}'.format(label_pair[1], scores[label_pair[0]].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likely overfitting and would need a less complex model to increase validation accuracy.\n",
    "\n",
    "We could use: Pre-pruning by reducing maximum depth. More trees, or smaller max_features to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare training and test accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The confusion matrix on the test set \n",
    "\n",
    "Your thoughts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make different mistakes than with `LogisticRegression()`. \n",
    "\n",
    "It might be time to go back to the features, or try a gradient boosted tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the different scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, X_train, y_train, cv=5, \n",
    "                        scoring='accuracy',\n",
    "                       return_train_score=True)\n",
    "\n",
    "print('Training Accuracy (all data): {:.3f}'.format(model.score(X_train, y_train)))\n",
    "\n",
    "print('Training Accuracy (cross-validation): {:.3f}'.format(scores['train_score'].mean()))\n",
    "\n",
    "print('Validation Accuracy (cross-validation): {:.3f}'.format(scores['test_score'].mean()))\n",
    "\n",
    "print('Test Accuracy (new data): {:.3f}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
