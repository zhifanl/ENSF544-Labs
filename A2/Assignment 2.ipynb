{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (40 marks total)\n",
    "### Due: February 13 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (20 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yellowbrick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 57)\n",
      "<bound method NDFrame.describe of       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0               0.21               0.28           0.50           0.0   \n",
      "1               0.06               0.00           0.71           0.0   \n",
      "2               0.00               0.00           0.00           0.0   \n",
      "3               0.00               0.00           0.00           0.0   \n",
      "4               0.00               0.00           0.00           0.0   \n",
      "...              ...                ...            ...           ...   \n",
      "4595            0.31               0.00           0.62           0.0   \n",
      "4596            0.00               0.00           0.00           0.0   \n",
      "4597            0.30               0.00           0.30           0.0   \n",
      "4598            0.96               0.00           0.00           0.0   \n",
      "4599            0.00               0.00           0.65           0.0   \n",
      "\n",
      "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0              0.14            0.28              0.21                0.07   \n",
      "1              1.23            0.19              0.19                0.12   \n",
      "2              0.63            0.00              0.31                0.63   \n",
      "3              0.63            0.00              0.31                0.63   \n",
      "4              1.85            0.00              0.00                1.85   \n",
      "...             ...             ...               ...                 ...   \n",
      "4595           0.00            0.31              0.00                0.00   \n",
      "4596           0.00            0.00              0.00                0.00   \n",
      "4597           0.00            0.00              0.00                0.00   \n",
      "4598           0.32            0.00              0.00                0.00   \n",
      "4599           0.00            0.00              0.00                0.00   \n",
      "\n",
      "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
      "0                0.00            0.94  ...                   0.0        0.000   \n",
      "1                0.64            0.25  ...                   0.0        0.010   \n",
      "2                0.31            0.63  ...                   0.0        0.000   \n",
      "3                0.31            0.63  ...                   0.0        0.000   \n",
      "4                0.00            0.00  ...                   0.0        0.000   \n",
      "...               ...             ...  ...                   ...          ...   \n",
      "4595             0.00            0.00  ...                   0.0        0.000   \n",
      "4596             0.00            0.00  ...                   0.0        0.000   \n",
      "4597             0.00            0.00  ...                   0.0        0.102   \n",
      "4598             0.00            0.00  ...                   0.0        0.000   \n",
      "4599             0.00            0.00  ...                   0.0        0.000   \n",
      "\n",
      "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0           0.132          0.0        0.372        0.180        0.048   \n",
      "1           0.143          0.0        0.276        0.184        0.010   \n",
      "2           0.137          0.0        0.137        0.000        0.000   \n",
      "3           0.135          0.0        0.135        0.000        0.000   \n",
      "4           0.223          0.0        0.000        0.000        0.000   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "4595        0.232          0.0        0.000        0.000        0.000   \n",
      "4596        0.000          0.0        0.353        0.000        0.000   \n",
      "4597        0.718          0.0        0.000        0.000        0.000   \n",
      "4598        0.057          0.0        0.000        0.000        0.000   \n",
      "4599        0.000          0.0        0.125        0.000        0.000   \n",
      "\n",
      "      capital_run_length_average  capital_run_length_longest  \\\n",
      "0                          5.114                         101   \n",
      "1                          9.821                         485   \n",
      "2                          3.537                          40   \n",
      "3                          3.537                          40   \n",
      "4                          3.000                          15   \n",
      "...                          ...                         ...   \n",
      "4595                       1.142                           3   \n",
      "4596                       1.555                           4   \n",
      "4597                       1.404                           6   \n",
      "4598                       1.147                           5   \n",
      "4599                       1.250                           5   \n",
      "\n",
      "      capital_run_length_total  \n",
      "0                         1028  \n",
      "1                         2259  \n",
      "2                          191  \n",
      "3                          191  \n",
      "4                           54  \n",
      "...                        ...  \n",
      "4595                        88  \n",
      "4596                        14  \n",
      "4597                       118  \n",
      "4598                        78  \n",
      "4599                        40  \n",
      "\n",
      "[4600 rows x 57 columns]>\n",
      "(4600,)\n",
      "<bound method NDFrame.describe of 0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "4595    0\n",
      "4596    0\n",
      "4597    0\n",
      "4598    0\n",
      "4599    0\n",
      "Name: is_spam, Length: 4600, dtype: int64>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library (0.5 marks)\n",
    "from yellowbrick import datasets\n",
    "X, y= datasets.load_spam()\n",
    "# TO DO: Print size and type of X and y (0.5 marks)\n",
    "print(X.shape)\n",
    "print(X.describe)\n",
    "\n",
    "print(y.shape)\n",
    "print(y.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (2 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary (1 mark)\n",
    "print(X.isnull().sum())\n",
    "\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **3%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "1863            0.00               0.00           0.00           0.0   \n",
      "525             0.14               0.14           0.29           0.0   \n",
      "2335            0.31               0.00           0.31           0.0   \n",
      "469             0.00               0.00           0.00           0.0   \n",
      "2811            0.00               0.00           0.00           0.0   \n",
      "...              ...                ...            ...           ...   \n",
      "1033            0.27               0.00           0.27           0.0   \n",
      "3264            0.49               0.00           0.00           0.0   \n",
      "1653            0.00               0.00           0.19           0.0   \n",
      "2607            0.00               0.00           0.00           0.0   \n",
      "2732            0.00               0.20           0.20           0.0   \n",
      "\n",
      "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "1863           0.00            0.00              0.00                0.00   \n",
      "525            0.00            0.00              0.00                0.00   \n",
      "2335           0.00            0.00              0.00                0.00   \n",
      "469            0.00            0.00              0.00                0.00   \n",
      "2811           0.00            0.00              0.00                0.00   \n",
      "...             ...             ...               ...                 ...   \n",
      "1033           0.00            0.00              0.00                0.00   \n",
      "3264           0.49            0.49              0.00                0.49   \n",
      "1653           0.00            0.00              0.19                0.00   \n",
      "2607           0.00            0.00              0.00                0.00   \n",
      "2732           0.00            0.00              0.00                0.00   \n",
      "\n",
      "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
      "1863             0.00            0.00  ...                  0.00        0.000   \n",
      "525              1.03            0.29  ...                  0.00        0.000   \n",
      "2335             0.00            0.00  ...                  0.00        0.000   \n",
      "469              0.00            0.00  ...                  0.00        0.000   \n",
      "2811             0.00            0.00  ...                  0.00        0.000   \n",
      "...               ...             ...  ...                   ...          ...   \n",
      "1033             0.00            0.00  ...                  0.00        0.000   \n",
      "3264             0.00            0.00  ...                  0.49        0.000   \n",
      "1653             0.00            0.00  ...                  0.00        0.015   \n",
      "2607             0.00            0.00  ...                  0.00        0.000   \n",
      "2732             0.00            0.00  ...                  0.20        0.000   \n",
      "\n",
      "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "1863        0.000        0.000        0.000        0.000        0.000   \n",
      "525         0.205        0.000        0.153        0.128        0.102   \n",
      "2335        0.000        0.051        0.000        0.000        0.000   \n",
      "469         0.000        0.000        5.844        0.000        0.000   \n",
      "2811        0.000        0.000        0.000        0.000        0.000   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "1033        0.000        0.000        0.874        0.051        0.051   \n",
      "3264        0.145        0.000        0.000        0.000        0.000   \n",
      "1653        0.137        0.000        0.061        0.000        0.000   \n",
      "2607        0.000        0.000        0.480        0.000        0.000   \n",
      "2732        0.087        0.000        0.000        0.000        0.000   \n",
      "\n",
      "      capital_run_length_average  capital_run_length_longest  \\\n",
      "1863                       1.235                           5   \n",
      "525                        2.686                          73   \n",
      "2335                       1.409                          12   \n",
      "469                        1.666                           5   \n",
      "2811                       2.333                           5   \n",
      "...                          ...                         ...   \n",
      "1033                       5.582                          61   \n",
      "3264                       1.641                          10   \n",
      "1653                       3.626                          44   \n",
      "2607                       2.000                           7   \n",
      "2732                       2.797                         127   \n",
      "\n",
      "      capital_run_length_total  \n",
      "1863                        21  \n",
      "525                        368  \n",
      "2335                        62  \n",
      "469                         15  \n",
      "2811                         7  \n",
      "...                        ...  \n",
      "1033                       374  \n",
      "3264                        87  \n",
      "1653                       990  \n",
      "2607                        26  \n",
      "2732                       512  \n",
      "\n",
      "[138 rows x 57 columns]>\n",
      "<bound method NDFrame.describe of 1863    0\n",
      "525     1\n",
      "2335    0\n",
      "469     1\n",
      "2811    0\n",
      "       ..\n",
      "1033    1\n",
      "3264    0\n",
      "1653    1\n",
      "2607    0\n",
      "2732    0\n",
      "Name: is_spam, Length: 138, dtype: int64>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Create X_small and y_small (1 mark)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_small, X_test_small, y_small, y_test_small = train_test_split(X, y, test_size=0.97, random_state=0)\n",
    "print(X_small.describe)\n",
    "print(y_small.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_large, X_test_large, y_large, y_test_large = train_test_split(X, y, random_state=0)\n",
    "model_1 = LogisticRegression(max_iter=2000)\n",
    "lr_1 = model_1.fit(X_large, y_large)\n",
    "linear_predictions_1= model_1.predict(X_test_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address\n",
       "0               0.21               0.28\n",
       "1               0.06               0.00\n",
       "2               0.00               0.00\n",
       "3               0.00               0.00\n",
       "4               0.00               0.00\n",
       "...              ...                ...\n",
       "4595            0.31               0.00\n",
       "4596            0.00               0.00\n",
       "4597            0.30               0.00\n",
       "4598            0.96               0.00\n",
       "4599            0.00               0.00\n",
       "\n",
       "[4600 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word_freq_make  word_freq_address\n",
      "321             0.00               0.62\n",
      "118             0.00               0.55\n",
      "261             0.00               0.00\n",
      "598             0.90               0.00\n",
      "1770            0.00               0.96\n",
      "...              ...                ...\n",
      "1033            0.27               0.00\n",
      "3264            0.49               0.00\n",
      "1653            0.00               0.00\n",
      "2607            0.00               0.00\n",
      "2732            0.00               0.20\n",
      "\n",
      "[3450 rows x 2 columns]\n",
      "      word_freq_make  word_freq_address\n",
      "991             0.00                0.0\n",
      "2824            1.16                0.0\n",
      "1906            0.00                0.0\n",
      "1471            0.00                0.0\n",
      "1813            0.00                0.0\n",
      "...              ...                ...\n",
      "196             0.17                0.0\n",
      "4315            0.00                0.0\n",
      "4550            0.00                0.0\n",
      "2941            0.00                0.0\n",
      "3987            0.00                0.0\n",
      "\n",
      "[1150 rows x 2 columns]\n",
      "321     1\n",
      "118     1\n",
      "261     1\n",
      "598     1\n",
      "1770    1\n",
      "       ..\n",
      "1033    1\n",
      "3264    0\n",
      "1653    1\n",
      "2607    0\n",
      "2732    0\n",
      "Name: is_spam, Length: 3450, dtype: int64\n",
      "991     1\n",
      "2824    0\n",
      "1906    0\n",
      "1471    1\n",
      "1813    0\n",
      "       ..\n",
      "196     1\n",
      "4315    0\n",
      "4550    0\n",
      "2941    0\n",
      "3987    0\n",
      "Name: is_spam, Length: 1150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_two_columns, X_test_two_columns, y_two_columns, y_test_two_columns = train_test_split(X.iloc[:, :2], y, random_state=0)\n",
    "\n",
    "print(X_two_columns)\n",
    "print(X_test_two_columns)\n",
    "\n",
    "print(y_two_columns)\n",
    "print(y_test_two_columns)\n",
    "\n",
    "model_2 = LogisticRegression(max_iter=2000)\n",
    "\n",
    "lr_2 = model_2.fit(X_two_columns, y_two_columns)\n",
    "\n",
    "linear_predictions_2 = lr_2.predict(X_test_two_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = LogisticRegression(max_iter=2000)\n",
    "\n",
    "lr_3 = model_3.fit(X_small, y_small)\n",
    "\n",
    "linear_predictions_3 = lr_3.predict(X_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.06260869565217392\n",
      "Root Mean Squared Error 0.2502172968684897\n",
      "lr.coef_:  [[-3.89249025e-01 -1.66420232e-01  1.77377083e-01  8.82788585e-01\n",
      "   5.23397196e-01  8.27890062e-01  2.10056267e+00  5.32431596e-01\n",
      "   6.33173016e-01  5.18289806e-02 -4.57228924e-01 -1.94759526e-01\n",
      "   2.13738814e-01  6.95840745e-02  1.17194923e+00  1.18694442e+00\n",
      "   8.60245216e-01  1.30482602e-01  9.01654954e-02  9.03683679e-01\n",
      "   1.84898819e-01  1.13171255e-01  1.92364428e+00  3.06842212e-01\n",
      "  -1.59228844e+00 -9.43918351e-01 -3.21063942e+00  4.24873649e-01\n",
      "  -1.31902939e+00 -1.50364327e-01 -1.65211277e+00  4.87187488e-02\n",
      "  -8.67339128e-01  1.48754156e-01 -1.54055052e+00  7.90789563e-01\n",
      "  -3.94247944e-02  1.13617558e-01 -7.27370741e-01 -8.03309657e-01\n",
      "  -1.38628505e+00 -1.85409115e+00 -6.25363189e-01 -1.23137543e+00\n",
      "  -7.19625885e-01 -1.54716905e+00 -6.21389400e-01 -1.60561177e+00\n",
      "  -9.92885186e-01 -1.83752190e-02 -6.46502275e-01  2.54256192e-01\n",
      "   3.14277111e+00  1.09094818e+00  2.22469973e-01  4.69244325e-03\n",
      "   5.37827869e-04]]\n",
      "lr.intercept_:  [-1.85979563]\n",
      "Training score: 0.93\n",
      "Validation score: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "linear_mae_1 = mean_absolute_error(y_test_large, linear_predictions_1)\n",
    "linear_rmae_1 = np.sqrt(mean_squared_error(y_test_large, linear_predictions_1))\n",
    "\n",
    "print(f\"Mean Absolute Error {linear_mae_1}\")\n",
    "print(f\"Root Mean Squared Error {linear_rmae_1}\")\n",
    "\n",
    "\n",
    "print(\"lr.coef_: \", lr_1.coef_)\n",
    "print(\"lr.intercept_: \", lr_1.intercept_)\n",
    "print(\"Training score: {:.2f}\".format(lr_1.score(X_large, y_large)))\n",
    "print(\"Validation score: {:.2f}\".format(lr_1.score(X_test_large, y_test_large)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.3869565217391304\n",
      "Root Mean Squared Error 0.6220582944862406\n",
      "lr.coef_:  [[ 0.76818503 -0.05128518]]\n",
      "lr.intercept_:  [-0.51083079]\n",
      "Training score: 0.61\n",
      "Validation score: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "linear_mae_2 = mean_absolute_error(y_test_two_columns, linear_predictions_2)\n",
    "linear_rmae_2 = np.sqrt(mean_squared_error(y_test_two_columns, linear_predictions_2))\n",
    "\n",
    "print(f\"Mean Absolute Error {linear_mae_2}\")\n",
    "print(f\"Root Mean Squared Error {linear_rmae_2}\")\n",
    "\n",
    "\n",
    "print(\"lr.coef_: \", lr_2.coef_)\n",
    "print(\"lr.intercept_: \", lr_2.intercept_)\n",
    "print(\"Training score: {:.2f}\".format(lr_2.score(X_two_columns, y_two_columns)))\n",
    "print(\"Validation score: {:.2f}\".format(lr_2.score(X_test_two_columns, y_test_two_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.09300761990138952\n",
      "Root Mean Squared Error 0.3049715067041338\n",
      "lr.coef_:  [[-4.71827835e-01 -1.79465240e-01 -1.42978569e-01  0.00000000e+00\n",
      "   6.78255736e-01  1.18576272e-01  9.88469394e-01  5.86769189e-01\n",
      "   7.93244899e-01 -5.19767406e-01  4.14747681e-02  9.28666234e-02\n",
      "   1.86657682e-02 -4.03197820e-02  4.37868893e-01  1.01300031e+00\n",
      "   6.94446247e-01  8.29146051e-01  2.90477030e-01  6.10793241e-01\n",
      "  -7.91009982e-02  2.43330876e-01  6.23662743e-01  1.17415295e+00\n",
      "  -1.28725123e+00 -4.11386667e-01 -6.84587353e-01 -2.36807266e-01\n",
      "  -2.10528482e-01 -2.26290418e-01 -2.38798180e-01 -1.44246532e-02\n",
      "  -5.57771572e-01 -1.44246532e-02 -1.83058860e-01  3.03453312e-01\n",
      "  -4.57279635e-01  2.21747653e-01 -3.98497925e-02 -1.40587621e-02\n",
      "  -2.65424587e-01 -6.32292119e-01 -7.30699819e-02 -4.58577872e-01\n",
      "  -3.75435017e-01 -3.64614589e-01 -4.38164220e-02 -5.70960323e-02\n",
      "  -1.37645129e-01 -1.66794006e-01 -1.36755460e-01  1.21497550e+00\n",
      "   6.76131614e-01 -1.54771282e-02  4.95205673e-01 -3.67951885e-03\n",
      "   5.63813389e-04]]\n",
      "lr.intercept_:  [-2.66073878]\n",
      "Training score: 0.96\n",
      "Validation score: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "linear_mae_3 = mean_absolute_error(y_test_small, linear_predictions_3)\n",
    "linear_rmae_3 = np.sqrt(mean_squared_error(y_test_small, linear_predictions_3))\n",
    "\n",
    "print(f\"Mean Absolute Error {linear_mae_3}\")\n",
    "print(f\"Root Mean Squared Error {linear_rmae_3}\")\n",
    "\n",
    "\n",
    "print(\"lr.coef_: \", lr_3.coef_)\n",
    "print(\"lr.intercept_: \", lr_3.intercept_)\n",
    "print(\"Training score: {:.2f}\".format(lr_3.score(X_small, y_small)))\n",
    "print(\"Validation score: {:.2f}\".format(lr_3.score(X_test_small, y_test_small)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5.1: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data size  Training Accuracy  Validation Accuracy\n",
      "0       3450           0.928696             0.937391\n",
      "1       3450           0.608406             0.613043\n",
      "2        138           0.963768             0.906992\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "import pandas as pd\n",
    "\n",
    "training_score_1 = lr_1.score(X_large, y_large)\n",
    "validation_score_1 = lr_1.score(X_test_large, y_test_large)\n",
    "results = pd.DataFrame(columns=[\"Data size\", \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "results.loc[len(results)]= {\"Data size\": len(X_large), \"Training Accuracy\": training_score_1, \"Validation Accuracy\": validation_score_1}\n",
    "\n",
    "training_score_2 = lr_2.score(X_two_columns, y_two_columns)\n",
    "validation_score_2 = lr_2.score(X_test_two_columns, y_test_two_columns)\n",
    "results.loc[len(results)] = {\"Data size\": len(X_two_columns), \"Training Accuracy\": training_score_2, \"Validation Accuracy\": validation_score_2}\n",
    "\n",
    "training_score_3 = lr_3.score(X_small, y_small)\n",
    "validation_score_3 = lr_3.score(X_test_small, y_test_small)\n",
    "results.loc[len(results)] = {\"Data size\": len(X_small), \"Training Accuracy\": training_score_3, \"Validation Accuracy\": validation_score_3}\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a54f",
   "metadata": {},
   "source": [
    "### Step 5.2: Visualize Classification Errors (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022252f",
   "metadata": {},
   "source": [
    "In this section, print the confusion matrix and the classification report to investigate the number of false positives vs. false negatives. Use the full dataset for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81931e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Retrieve target vector and predicted values for validation set using full dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "# HINT: To remove scientific notation from a heatmap, set the parameter fmt='d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Print classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "1. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "1. Based on your answer to question 2, would you want to maximize precision or recall? How would you do this?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 2: Regression (15 marks)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library (0.5 marks)\n",
    "\n",
    "# TO DO: Print size and type of X and y (0.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1 mark)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (2 marks)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4da0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (2 marks)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "1. Could we tell if this model was a good fit by using just the mean squared error? Why or why not?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c484f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
