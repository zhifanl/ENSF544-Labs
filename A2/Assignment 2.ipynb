{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (40 marks total)\n",
    "### Due: February 13 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (20 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yellowbrick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 57)\n",
      "(4600,)\n",
      "***************************\n",
      "262200\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4600\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library (0.5 marks)\n",
    "from yellowbrick import datasets\n",
    "X, y= datasets.load_spam()\n",
    "print(X.shape)\n",
    "# print(X.describe)\n",
    "\n",
    "\n",
    "print(y.shape)\n",
    "# print(y.describe)\n",
    "\n",
    "\n",
    "# TO DO: Print size and type of X and y (0.5 marks)\n",
    "print(\"***************************\")\n",
    "print(X.size)\n",
    "print(type(X))\n",
    "\n",
    "print(y.size)\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (2 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary (1 mark)\n",
    "print(X.isnull().sum())\n",
    "\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **3%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small (1 mark)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_small, X_test_small, y_small, y_test_small = train_test_split(X, y, test_size=0.97, random_state=0)\n",
    "# print(X_small.describe)\n",
    "# print(y_small.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_large, X_test_large, y_large, y_test_large = train_test_split(X, y, random_state=0)\n",
    "model_1 = LogisticRegression(max_iter=2000)\n",
    "lr_1 = model_1.fit(X_large, y_large)\n",
    "linear_predictions_1= model_1.predict(X_test_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address\n",
       "0               0.21               0.28\n",
       "1               0.06               0.00\n",
       "2               0.00               0.00\n",
       "3               0.00               0.00\n",
       "4               0.00               0.00\n",
       "...              ...                ...\n",
       "4595            0.31               0.00\n",
       "4596            0.00               0.00\n",
       "4597            0.30               0.00\n",
       "4598            0.96               0.00\n",
       "4599            0.00               0.00\n",
       "\n",
       "[4600 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word_freq_make  word_freq_address\n",
      "321             0.00               0.62\n",
      "118             0.00               0.55\n",
      "261             0.00               0.00\n",
      "598             0.90               0.00\n",
      "1770            0.00               0.96\n",
      "...              ...                ...\n",
      "1033            0.27               0.00\n",
      "3264            0.49               0.00\n",
      "1653            0.00               0.00\n",
      "2607            0.00               0.00\n",
      "2732            0.00               0.20\n",
      "\n",
      "[3450 rows x 2 columns]\n",
      "      word_freq_make  word_freq_address\n",
      "991             0.00                0.0\n",
      "2824            1.16                0.0\n",
      "1906            0.00                0.0\n",
      "1471            0.00                0.0\n",
      "1813            0.00                0.0\n",
      "...              ...                ...\n",
      "196             0.17                0.0\n",
      "4315            0.00                0.0\n",
      "4550            0.00                0.0\n",
      "2941            0.00                0.0\n",
      "3987            0.00                0.0\n",
      "\n",
      "[1150 rows x 2 columns]\n",
      "321     1\n",
      "118     1\n",
      "261     1\n",
      "598     1\n",
      "1770    1\n",
      "       ..\n",
      "1033    1\n",
      "3264    0\n",
      "1653    1\n",
      "2607    0\n",
      "2732    0\n",
      "Name: is_spam, Length: 3450, dtype: int64\n",
      "991     1\n",
      "2824    0\n",
      "1906    0\n",
      "1471    1\n",
      "1813    0\n",
      "       ..\n",
      "196     1\n",
      "4315    0\n",
      "4550    0\n",
      "2941    0\n",
      "3987    0\n",
      "Name: is_spam, Length: 1150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_two_columns, X_test_two_columns, y_two_columns, y_test_two_columns = train_test_split(X.iloc[:, :2], y, random_state=0)\n",
    "\n",
    "print(X_two_columns)\n",
    "print(X_test_two_columns)\n",
    "\n",
    "print(y_two_columns)\n",
    "print(y_test_two_columns)\n",
    "\n",
    "model_2 = LogisticRegression(max_iter=2000)\n",
    "\n",
    "lr_2 = model_2.fit(X_two_columns, y_two_columns)\n",
    "\n",
    "linear_predictions_2 = lr_2.predict(X_test_two_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = LogisticRegression(max_iter=2000)\n",
    "\n",
    "lr_3 = model_3.fit(X_small, y_small)\n",
    "\n",
    "linear_predictions_3 = lr_3.predict(X_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.06260869565217392\n",
      "Root Mean Squared Error 0.2502172968684897\n",
      "lr.coef_:  [[-3.89249025e-01 -1.66420232e-01  1.77377083e-01  8.82788585e-01\n",
      "   5.23397196e-01  8.27890062e-01  2.10056267e+00  5.32431596e-01\n",
      "   6.33173016e-01  5.18289806e-02 -4.57228924e-01 -1.94759526e-01\n",
      "   2.13738814e-01  6.95840745e-02  1.17194923e+00  1.18694442e+00\n",
      "   8.60245216e-01  1.30482602e-01  9.01654954e-02  9.03683679e-01\n",
      "   1.84898819e-01  1.13171255e-01  1.92364428e+00  3.06842212e-01\n",
      "  -1.59228844e+00 -9.43918351e-01 -3.21063942e+00  4.24873649e-01\n",
      "  -1.31902939e+00 -1.50364327e-01 -1.65211277e+00  4.87187488e-02\n",
      "  -8.67339128e-01  1.48754156e-01 -1.54055052e+00  7.90789563e-01\n",
      "  -3.94247944e-02  1.13617558e-01 -7.27370741e-01 -8.03309657e-01\n",
      "  -1.38628505e+00 -1.85409115e+00 -6.25363189e-01 -1.23137543e+00\n",
      "  -7.19625885e-01 -1.54716905e+00 -6.21389400e-01 -1.60561177e+00\n",
      "  -9.92885186e-01 -1.83752190e-02 -6.46502275e-01  2.54256192e-01\n",
      "   3.14277111e+00  1.09094818e+00  2.22469973e-01  4.69244325e-03\n",
      "   5.37827869e-04]]\n",
      "lr.intercept_:  [-1.85979563]\n",
      "Training score: 0.93\n",
      "Validation score: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "linear_mae_1 = mean_absolute_error(y_test_large, linear_predictions_1)\n",
    "linear_rmae_1 = np.sqrt(mean_squared_error(y_test_large, linear_predictions_1))\n",
    "\n",
    "print(f\"Mean Absolute Error {linear_mae_1}\")\n",
    "print(f\"Root Mean Squared Error {linear_rmae_1}\")\n",
    "\n",
    "\n",
    "print(\"lr.coef_: \", lr_1.coef_)\n",
    "print(\"lr.intercept_: \", lr_1.intercept_)\n",
    "print(\"Training score: {:.2f}\".format(lr_1.score(X_large, y_large)))\n",
    "print(\"Validation score: {:.2f}\".format(lr_1.score(X_test_large, y_test_large)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.3869565217391304\n",
      "Root Mean Squared Error 0.6220582944862406\n",
      "lr.coef_:  [[ 0.76818503 -0.05128518]]\n",
      "lr.intercept_:  [-0.51083079]\n",
      "Training score: 0.61\n",
      "Validation score: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "linear_mae_2 = mean_absolute_error(y_test_two_columns, linear_predictions_2)\n",
    "linear_rmae_2 = np.sqrt(mean_squared_error(y_test_two_columns, linear_predictions_2))\n",
    "\n",
    "print(f\"Mean Absolute Error {linear_mae_2}\")\n",
    "print(f\"Root Mean Squared Error {linear_rmae_2}\")\n",
    "\n",
    "\n",
    "print(\"lr.coef_: \", lr_2.coef_)\n",
    "print(\"lr.intercept_: \", lr_2.intercept_)\n",
    "print(\"Training score: {:.2f}\".format(lr_2.score(X_two_columns, y_two_columns)))\n",
    "print(\"Validation score: {:.2f}\".format(lr_2.score(X_test_two_columns, y_test_two_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.09300761990138952\n",
      "Root Mean Squared Error 0.3049715067041338\n",
      "lr.coef_:  [[-4.71827835e-01 -1.79465240e-01 -1.42978569e-01  0.00000000e+00\n",
      "   6.78255736e-01  1.18576272e-01  9.88469394e-01  5.86769189e-01\n",
      "   7.93244899e-01 -5.19767406e-01  4.14747681e-02  9.28666234e-02\n",
      "   1.86657682e-02 -4.03197820e-02  4.37868893e-01  1.01300031e+00\n",
      "   6.94446247e-01  8.29146051e-01  2.90477030e-01  6.10793241e-01\n",
      "  -7.91009982e-02  2.43330876e-01  6.23662743e-01  1.17415295e+00\n",
      "  -1.28725123e+00 -4.11386667e-01 -6.84587353e-01 -2.36807266e-01\n",
      "  -2.10528482e-01 -2.26290418e-01 -2.38798180e-01 -1.44246532e-02\n",
      "  -5.57771572e-01 -1.44246532e-02 -1.83058860e-01  3.03453312e-01\n",
      "  -4.57279635e-01  2.21747653e-01 -3.98497925e-02 -1.40587621e-02\n",
      "  -2.65424587e-01 -6.32292119e-01 -7.30699819e-02 -4.58577872e-01\n",
      "  -3.75435017e-01 -3.64614589e-01 -4.38164220e-02 -5.70960323e-02\n",
      "  -1.37645129e-01 -1.66794006e-01 -1.36755460e-01  1.21497550e+00\n",
      "   6.76131614e-01 -1.54771282e-02  4.95205673e-01 -3.67951885e-03\n",
      "   5.63813389e-04]]\n",
      "lr.intercept_:  [-2.66073878]\n",
      "Training score: 0.96\n",
      "Validation score: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "linear_mae_3 = mean_absolute_error(y_test_small, linear_predictions_3)\n",
    "linear_rmae_3 = np.sqrt(mean_squared_error(y_test_small, linear_predictions_3))\n",
    "\n",
    "print(f\"Mean Absolute Error {linear_mae_3}\")\n",
    "print(f\"Root Mean Squared Error {linear_rmae_3}\")\n",
    "\n",
    "\n",
    "print(\"lr.coef_: \", lr_3.coef_)\n",
    "print(\"lr.intercept_: \", lr_3.intercept_)\n",
    "print(\"Training score: {:.2f}\".format(lr_3.score(X_small, y_small)))\n",
    "print(\"Validation score: {:.2f}\".format(lr_3.score(X_test_small, y_test_small)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5.1: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data size  Training Accuracy  Validation Accuracy\n",
      "0       3450           0.928696             0.937391\n",
      "1       3450           0.608406             0.613043\n",
      "2        138           0.963768             0.906992\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "import pandas as pd\n",
    "\n",
    "training_score_1 = lr_1.score(X_large, y_large)\n",
    "validation_score_1 = lr_1.score(X_test_large, y_test_large)\n",
    "results = pd.DataFrame(columns=[\"Data size\", \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "results.loc[len(results)]= {\"Data size\": len(X_large), \"Training Accuracy\": training_score_1, \"Validation Accuracy\": validation_score_1}\n",
    "\n",
    "training_score_2 = lr_2.score(X_two_columns, y_two_columns)\n",
    "validation_score_2 = lr_2.score(X_test_two_columns, y_test_two_columns)\n",
    "results.loc[len(results)] = {\"Data size\": len(X_two_columns), \"Training Accuracy\": training_score_2, \"Validation Accuracy\": validation_score_2}\n",
    "\n",
    "training_score_3 = lr_3.score(X_small, y_small)\n",
    "validation_score_3 = lr_3.score(X_test_small, y_test_small)\n",
    "results.loc[len(results)] = {\"Data size\": len(X_small), \"Training Accuracy\": training_score_3, \"Validation Accuracy\": validation_score_3}\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a54f",
   "metadata": {},
   "source": [
    "### Step 5.2: Visualize Classification Errors (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022252f",
   "metadata": {},
   "source": [
    "In this section, print the confusion matrix and the classification report to investigate the number of false positives vs. false negatives. Use the full dataset for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81931e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Retrieve target vector and predicted values for validation set using full dataset \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create confusion matrices for the RF model\n",
    "cm_rf = confusion_matrix(y_test_large, linear_predictions_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4cb30f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "# HINT: To remove scientific notation from a heatmap, set the parameter fmt='d'\n",
    "# Set up the figure size using subplots\n",
    "fig, axes = plt.subplots(figsize = (10,5))\n",
    "# Create a heatmap for Random Forest\n",
    "sns.heatmap(cm_rf, annot=True, fmt = 'd', cmap='Blues', ax=axes)\n",
    "axes.set_title(\"Confusion Matrix\")\n",
    "axes.set_xlabel(\"Predicted\")\n",
    "axes.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bfb397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       692\n",
      "           1       0.93      0.91      0.92       458\n",
      "\n",
      "    accuracy                           0.94      1150\n",
      "   macro avg       0.94      0.93      0.93      1150\n",
      "weighted avg       0.94      0.94      0.94      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_large, linear_predictions_1,\n",
    "                           zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error 0.06260869565217392\n",
    "Root Mean Squared Error 0.2502172968684897\n",
    "lr.intercept_:  [-1.85979563]\n",
    "Training score: 0.93\n",
    "Validation score: 0.94\n",
    "\n",
    "\n",
    "\n",
    "Mean Absolute Error 0.3869565217391304\n",
    "Root Mean Squared Error 0.6220582944862406\n",
    "lr.coef_:  [[ 0.76818503 -0.05128518]]\n",
    "lr.intercept_:  [-0.51083079]\n",
    "Training score: 0.61\n",
    "Validation score: 0.61\n",
    "\n",
    "\n",
    "Mean Absolute Error 0.09300761990138952\n",
    "Root Mean Squared Error 0.3049715067041338\n",
    "lr.intercept_:  [-2.66073878]\n",
    "Training score: 0.96\n",
    "Validation score: 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "1. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "1. Based on your answer to question 2, would you want to maximize precision or recall? How would you do this?\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. \n",
    "- training set with full dataset X and y:\n",
    "The training score is 0.93, and the validation score is 0.94. This means the model performs well on both the training and unseen data, means a good model and generalizes well.\n",
    "- training set with first two columns from X:\n",
    "training and testing are both 0.61, the reduction limits the model to get the variance, model has high biases and low variance. The model is underfitting, meaning it is too simple and does not capture the underlying patterns in the data well.\n",
    "- training set with 97% training data and 3% testing data:\n",
    "Using a small portion of the data as the testing set, makes the training score increases to 0.96, but the validation score decreases to 0.91 compared to using the full dataset. The high training score suggests that with less data to validate, the model can fit the training data better, but the slight decrease in validation score might indicate that the model has less data to validate its predictions, which could potentially lead to overfitting.\n",
    "\n",
    "2. False positive means model predicts 1, but actual value is 0. false negative means model predicts 0, but actual is 1. In my opinion false negative is worse. Because if the model fails to predict a spam. the spam content will be actually released. false positive will not let spam be released even the model censors non-spam contents. (False positives are more undesirable because you can potentially miss a very important email. You need to increase precision.)\n",
    "\n",
    "3. I would like to maximize precision because we want to have more positive results. Recall is the ratio of true positive predictions to true positives and false negatives. To do it, I could adjust the model's threshold to be more lenient in classifying positives, ensuring fewer false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*\n",
    "\n",
    "1. Where did you source your code?\n",
    "- Based on lecture materials and labs.\n",
    "1. In what order did you complete the steps?\n",
    "- Try to come up with solutions by myself. If I see challenges. Ex: cannot memorize a function's parameters, or don't know which method to use, I will google or go to lecture code examples.\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "- I ask specific questions, not copy and paste the content to the AI. Yes I need to modify the code to help me memorize what it does. then next time I don't need to ask ai.\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "- I had challenges classifying recall and precision so I asked AI to generate some study material for me. At the end I know how to classify them and how to adjust based on requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 2: Regression (15 marks)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 8)\n",
      "<bound method NDFrame.describe of       cement   slag    ash  water  splast  coarse   fine  age\n",
      "0      540.0    0.0    0.0  162.0     2.5  1040.0  676.0   28\n",
      "1      540.0    0.0    0.0  162.0     2.5  1055.0  676.0   28\n",
      "2      332.5  142.5    0.0  228.0     0.0   932.0  594.0  270\n",
      "3      332.5  142.5    0.0  228.0     0.0   932.0  594.0  365\n",
      "4      198.6  132.4    0.0  192.0     0.0   978.4  825.5  360\n",
      "...      ...    ...    ...    ...     ...     ...    ...  ...\n",
      "1025   276.4  116.0   90.3  179.6     8.9   870.1  768.3   28\n",
      "1026   322.2    0.0  115.6  196.0    10.4   817.9  813.4   28\n",
      "1027   148.5  139.4  108.6  192.7     6.1   892.4  780.0   28\n",
      "1028   159.1  186.7    0.0  175.6    11.3   989.6  788.9   28\n",
      "1029   260.9  100.5   78.3  200.6     8.6   864.5  761.5   28\n",
      "\n",
      "[1030 rows x 8 columns]>\n",
      "(1030,)\n",
      "<bound method NDFrame.describe of 0       79.986111\n",
      "1       61.887366\n",
      "2       40.269535\n",
      "3       41.052780\n",
      "4       44.296075\n",
      "          ...    \n",
      "1025    44.284354\n",
      "1026    31.178794\n",
      "1027    23.696601\n",
      "1028    32.768036\n",
      "1029    32.401235\n",
      "Name: strength, Length: 1030, dtype: float64>\n",
      "***************************\n",
      "8240\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "1030\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library (0.5 marks)\n",
    "from yellowbrick import datasets\n",
    "X, y= datasets.load_concrete()\n",
    "# TO DO: Print size and type of X and y (0.5 marks)\n",
    "print(X.shape)\n",
    "print(X.describe)\n",
    "\n",
    "print(y.shape)\n",
    "print(y.describe)\n",
    "# TO DO: Print size and type of X and y (0.5 marks)\n",
    "print(\"***************************\")\n",
    "\n",
    "print(X.size)\n",
    "print(type(X))\n",
    "\n",
    "print(y.size)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1 mark)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06fc9c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(X.isnull().sum())\n",
    "\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (2 marks)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba4da0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "lr_2 = model.fit(X_train, y_train)\n",
    "linear_predictions_2 = lr_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (2 marks)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 7.8652986058082055\n",
      "Root Mean Squared Error 9.779332023553767\n",
      "Training score: 0.61\n",
      "Validation score: 0.64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "linear_mae_2 = mean_absolute_error(y_test, linear_predictions_2)\n",
    "linear_rmae_2 = np.sqrt(mean_squared_error(y_test, linear_predictions_2))\n",
    "\n",
    "print(f\"Mean Absolute Error {linear_mae_2}\")\n",
    "print(f\"Root Mean Squared Error {linear_rmae_2}\")\n",
    "\n",
    "print(\"Training score: {:.2f}\".format(lr_2.score(X_train, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(lr_2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59ae0f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training accuracy  Validation accuracy       MSE        R2\n",
      "0           0.609071             0.636898  7.865299  9.779332\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data = {\n",
    "    'Training accuracy': [lr_2.score(X_train, y_train)],\n",
    "    'Validation accuracy': [lr_2.score(X_test, y_test)],\n",
    "    'MSE': [linear_mae_2],\n",
    "    'R2': [linear_rmae_2]\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(data)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "1. Could we tell if this model was a good fit by using just the mean squared error? Why or why not?\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. It doesn't produce good result. The model is not the right model. MSE, R Square are way off from what we expect. I suspect there are noises in the data set. \n",
    "2. We cannot, MSE does not indicate how much of the variance in the target variable the model accounts for. MSE is highly sensitive to outliers because it squares the errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*\n",
    "1. Where did you source your code?\n",
    "- Based on the previous Question 1's code.\n",
    "1. In what order did you complete the steps?\n",
    "- Try to come up with solutions by myself. For example, try to implement a ML model and do some prediction then evaluate the model based on several scores. I met challenges. Ex: I forgot why MSE shouldn't be the only metric to evaluate model is good fit or not. I google it and ask AI to give me more details.\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "- I ask specific questions, not copy and paste the content to the AI. I ask AI to teach me the concepts so that I can grasp it. I didn't modify code because I didn't put any code in the AI. I tried to do things by myself this time.\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "- I had challenges with linear regression model. I was surprised by MSE, R2, and the score. so I asked AI to generate some potential reasons for me. At the end I know what are the factors that could cause this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "low training score & low validation score (0.61 & 0.62) means underfitting and low variance. Need more data and more variance. \n",
    "\n",
    "validation score goes down probably indicates a potential of overfitting and need more test data to validate score.\n",
    "\n",
    "maximizing precision means reducing false positive\n",
    "\n",
    "maximizing recall means reducing false negative\n",
    "\n",
    "To get higher precision rate, one strategy is to train model to treat positive data leniently, to make more data positive.\n",
    "\n",
    "sometimes noises & outliers in the dataset could significantly impact MSE. Cannot evaluate a model only based on MSE. A model could have a high MSE if it fails to predict outliers accurately, even if it performs well for the majority of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "Working on this assignment, I found the process of exploring ML concepts and breaking them down into understandable explanations particularly motivating and interesting. I learned a lot and memorized lots of concepts by doing this assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
